{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "summarization.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9_YY5dr_YNc"
      },
      "source": [
        "train_source = open('/content/drive/MyDrive/Copy of train.txt.src.tokenized.fixed.cleaned.final.truncated').read()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLf-0v0-Akgw"
      },
      "source": [
        "train_source = train_source.split('\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "5fvga1S4DC5h",
        "outputId": "f600f809-fc23-4d72-8781-64ee8cdc8389"
      },
      "source": [
        "train_source.pop()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "''"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Gx_ydCz2ROR"
      },
      "source": [
        "train_target = open('/content/drive/MyDrive/Copy of train.txt.tgt.tokenized.fixed.cleaned.final.truncated').read()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zcIJzRM2TAv"
      },
      "source": [
        "train_target = train_target.split(\"\\n– \")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_OPfd74I0aLL",
        "outputId": "88130da9-3f98-4dac-8b25-d41a7e9bcedf"
      },
      "source": [
        "print(len(train_source))\r\n",
        "len(train_target)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "44972\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "44972"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_2ucK460OhE"
      },
      "source": [
        "!pip install rouge"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0etWtW3PP_U"
      },
      "source": [
        "!pip install sentence_transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11kNrNmpBuIP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60099cfd-fa5d-4fcc-9ef8-55c05082df5f"
      },
      "source": [
        "import nltk\r\n",
        "from nltk import sent_tokenize,word_tokenize\r\n",
        "nltk.download('punkt')\r\n",
        "import numpy as np\r\n",
        "from sentence_transformers import SentenceTransformer\r\n",
        "import math\r\n",
        "from rouge import Rouge \r\n",
        "sbert_model = SentenceTransformer('bert-base-nli-mean-tokens')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 405M/405M [00:20<00:00, 20.3MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5iFFZp_hGcY"
      },
      "source": [
        "def cosine(u, v):\r\n",
        "    return np.dot(u, v) / (np.linalg.norm(u) * np.linalg.norm(v))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxYeUn9nHGX7"
      },
      "source": [
        "def convert_to_embeddings(hypothesis):\r\n",
        "  text = hypothesis\r\n",
        "  hypothesis_embeddings = {}\r\n",
        "  hypothesis = sent_tokenize(hypothesis)\r\n",
        "  sum = 0\r\n",
        "  for sent in hypothesis:\r\n",
        "    var = sbert_model.encode([sent])[0]\r\n",
        "    sum+=var\r\n",
        "    hypothesis_embeddings[sent] = var\r\n",
        "\r\n",
        "  centroid = sum/len(hypothesis)\r\n",
        "  #print(\"done\")\r\n",
        "  #print(hypothesis_embeddings)\r\n",
        "  content_relevance_score = content_relevance(centroid,hypothesis_embeddings)\r\n",
        "  sentence_novelty_score = sentence_novelty(content_relevance_score,hypothesis_embeddings)\r\n",
        "  sentence_position_score = sentence_position(hypothesis)\r\n",
        "  return total_score(content_relevance_score,sentence_novelty_score,sentence_position_score,text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzrcCZpZiyrX"
      },
      "source": [
        "def content_relevance(centroid,hypothesis_embeddings):\r\n",
        "  d = {}\r\n",
        "  for sentence,embed in hypothesis_embeddings.items():\r\n",
        "    d[sentence] = cosine(centroid,embed)\r\n",
        "  return d"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQwPhgV2jZgp"
      },
      "source": [
        "def sentence_novelty(content_relevance_score,hypothesis_embeddings):\r\n",
        "  novel_sentences = {}\r\n",
        "  TAU = 0.95\r\n",
        "  for sent1,embed1 in hypothesis_embeddings.items():\r\n",
        "    max_similarity = 0\r\n",
        "    for sent2,embed2 in hypothesis_embeddings.items():\r\n",
        "      if sent1!=sent2 and cosine(embed1,embed2)>max_similarity:\r\n",
        "          max_similarity = cosine(embed1,embed2)\r\n",
        "\r\n",
        "    if max_similarity<TAU:\r\n",
        "      novel_sentences[sent1] = 1\r\n",
        "\r\n",
        "    if max_similarity>TAU:\r\n",
        "      if content_relevance_score[sent1]>content_relevance_score[sent2]:\r\n",
        "        novel_sentences[sent1] = 1\r\n",
        "      else:\r\n",
        "        novel_sentences[sent2] = 1\r\n",
        "\r\n",
        "    else:\r\n",
        "      novel_sentences[sent1] = 1-max_similarity\r\n",
        "  return novel_sentences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2aqlZodSk8t"
      },
      "source": [
        "def sentence_position(hypothesis):\r\n",
        "  score_sent = {}\r\n",
        "  for i,sent in enumerate(hypothesis):\r\n",
        "    score_sent[sent] = max(0.5,math.exp(-(i+1)/(len(hypothesis)**(1/3))))\r\n",
        "  return score_sent"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJG7xg9XJX5f"
      },
      "source": [
        "def total_score(content_relevance_score,sentence_novelty_score,sentence_position_score,text):\r\n",
        "  ALPHA = 0.6\r\n",
        "  BETA = 0.2\r\n",
        "  GAMMA = 0.2\r\n",
        "  final_score = {}\r\n",
        "  for sent in content_relevance_score:\r\n",
        "    final_score[sent] = ALPHA*content_relevance_score[sent]+BETA*sentence_novelty_score[sent]+GAMMA*sentence_position_score[sent]\r\n",
        "  final_score = {k: v for k, v in sorted(final_score.items(), key=lambda item: item[1],reverse=True)}\r\n",
        "  summary = \"\"\r\n",
        "  for sent in final_score:\r\n",
        "    if len(summary)<len(text)//2: #making summary of approx half length.\r\n",
        "      summary+=sent\r\n",
        "  return summary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ddRr74t2UOn"
      },
      "source": [
        "def evaluate(predicted_summary,actual_summary):\r\n",
        "  rouge = Rouge()\r\n",
        "  score = rouge.get_scores(predicted_summary,actual_summary)\r\n",
        "  print(score[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8wT9P6uR7VR",
        "outputId": "b1d28de6-110e-45dc-ebaa-521fbc3a2ebf"
      },
      "source": [
        "text = train_source[3]\r\n",
        "actual_summary = train_target[3]\r\n",
        "predicted_summary = convert_to_embeddings(text)\r\n",
        "print(\"Length of text \",len(text))\r\n",
        "print(\"length of summary\",len(predicted_summary))\r\n",
        "print(predicted_summary)\r\n",
        "evaluate(predicted_summary,actual_summary)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of text  2681\n",
            "length of summary 1430\n",
            "unfortunately for him , many people had already seen it and responded .he deleted the original ( which is why i had to link to a retweet ) obviously aware that what he had posted was wrong .unfortunately for him , many people had already seen ittucker carlson exposes his own sexism on twitter ( updated ) tucker carlson has done some good work in the past … his site , the daily caller , is a frequent stop of mine and many other conservatives .if you haven ’ t heard by now , monday evening , tucker carlson posted a disturbing tweet about governor palin which said : palin ’ s popularity falling in iowa , but maintains lead to become supreme commander of milfistan aside from tucker ’ s sheep-like response to warped poll numbers , he also failed to take ownership of his sexist comment .this is also why i am so angered by tucker ’ s recent actions .” but that wasn ’ t enough to spare him the ire of conservative women on the blogosphere and twitter .learn more story_separator_special_tag i am not down with @karlrove @tuckercarlson misogynist mockery of @sarahpalinusa .on tuesday , before carlson ’ s first apology , stacy drake , writing on conservatives4palin , praised carlson ’ s works at the daily caller , particularly the leaks of the journolist emails , saying that ’ s why his tweet stung so badly .palin ' s popularity falling in iowa , but maintains lead to become supreme commander of milfistan , \" he wrote .\n",
            "{'rouge-1': {'f': 0.4282655196997556, 'p': 0.3816793893129771, 'r': 0.4878048780487805}, 'rouge-2': {'f': 0.11612902733319479, 'p': 0.10344827586206896, 'r': 0.1323529411764706}, 'rouge-l': {'f': 0.39426522798936303, 'p': 0.3741496598639456, 'r': 0.4166666666666667}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "ugPVfqsPQnGY",
        "outputId": "a7faad31-4a25-489a-ff13-aa0fec6c1918"
      },
      "source": [
        "train_source[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'los angeles ( ap ) — in her first interview since the nba banned her estranged husband , shelly sterling says she will fight to keep her share of the los angeles clippers and plans one day to divorce donald sterling . ( click prev or next to continue viewing images. ) advertisement ( click prev or next to continue viewing images. ) los angeles clippers co-owner shelly sterling , below , watches the clippers play the oklahoma city thunder along with her attorney , pierce o \\' donnell , in the first half of game 3 of the western conference ... ( associated press ) shelly sterling spoke to barbara walters , and abc news posted a short story with excerpts from the conversation sunday . nba commissioner adam silver has banned donald sterling for making racist comments and urged owners to force sterling to sell the team . silver added that no decisions had been made about the rest of sterling \\' s family . according to abc \\' s story , shelly sterling told walters : \" i will fight that decision . \" sterling also said that she \" eventually \" will divorce her husband , and that she hadn \\' t yet done so due to financial considerations . story_separator_special_tag shelly sterling said today that \" eventually , i am going to \" divorce her estranged husband , donald sterling , and if the nba tries to force her to sell her half of the los angeles clippers , she would \" absolutely \" fight to keep her stake in the team . \" i will fight that decision , \" she told abc news \\' barbara walters today in an exclusive interview . \" to be honest with you , i \\' m wondering if a wife of one of the owners , and there \\' s 30 owners , did something like that , said those racial slurs , would they oust the husband ? or would they leave the husband in ? \" sterling added that the clippers franchise is her \" passion \" and \" legacy to my family . \" \" i \\' ve been with the team for 33 years , through the good times and the bad times , \" she added . these comments come nearly two weeks after nba commissioner adam silver announced a lifetime ban and a $ 2.5 million fine for donald sterling on april 29 , following racist comments from the 80-year-old , which were caught on tape and released to the media . read : barbara walters \\' exclusive interview with v. stiviano being estranged from her husband , shelly sterling said she would \" have to accept \" whatever punishment the nba handed down to him , but that her stake in the team should be separate . \" i was shocked by what he said . and -- well , i guess whatever their decision is -- we have to live'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w15ZmvmNQygn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}